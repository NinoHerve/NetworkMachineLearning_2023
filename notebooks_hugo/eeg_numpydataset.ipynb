{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from utils.dataset import EEGDataset\n",
    "from torcheeg.datasets import NumpyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to eeg dataset\n",
    "eeg_dir  = Path('../EEGDataset')\n",
    "\n",
    "# subjects\n",
    "subjects = ['sub-01', 'sub-02', 'sub-03', 'sub-04']\n",
    "\n",
    "# dataset using only selected subjects\n",
    "dataset = EEGDataset(eeg_dir, subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = []\n",
    "labels = []\n",
    "for f,_ in enumerate(dataset.files):\n",
    "    sample = dataset.__getitem__(f)\n",
    "    epochs.append(sample.get('eeg'))\n",
    "    labels.append(sample.get('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X : (2225, 128, 625)\n",
      "Shape of y : (2225,)\n"
     ]
    }
   ],
   "source": [
    "X = np.stack(epochs, axis=0)\n",
    "y = np.stack(labels, axis=0)\n",
    "print('Shape of X : ' + str(X.shape))\n",
    "print('Shape of y : ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = {'trial_type':y}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the adjacency matrix to use as transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = np.load('../utils/electrodes_adj.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheeg import transforms\n",
    "from torcheeg.transforms.pyg import ToG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NUMPY]: 100%|██████████| 22/22 [00:25<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait for the writing process to complete...\n"
     ]
    }
   ],
   "source": [
    "dataset = NumpyDataset(X=X,\n",
    "                       y=y,\n",
    "                       io_path = '../data_io/',\n",
    "                       io_size=10485760*2,\n",
    "                       offline_transform=transforms.BandDifferentialEntropy(),\n",
    "                       online_transform=ToG(adj),\n",
    "                       label_transform=transforms.Compose([\n",
    "                           transforms.Select('trial_type'),\n",
    "                           transforms.Lambda(lambda x: int(x) + 1),\n",
    "                       ]),                       \n",
    "                       num_worker=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheeg.model_selection import KFold\n",
    "\n",
    "k_fold = KFold(n_splits=5,\n",
    "               split_path=f'./tmp_out/split',\n",
    "               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_channels=4, num_layers=3, hid_channels=64, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(in_channels, hid_channels)\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(GATConv(hid_channels, hid_channels))\n",
    "        self.lin1 = nn.Linear(hid_channels, hid_channels)\n",
    "        self.lin2 = nn.Linear(hid_channels, num_classes)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        self.lin1.reset_parameters()\n",
    "        self.lin2.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        for conv in self.convs:\n",
    "            x = F.relu(conv(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        X = batch[0].to(device)\n",
    "        y = batch[1].to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            loss, current = loss.item(), batch_idx * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def valid(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X = batch[0].to(device)\n",
    "            y = batch[1].to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            val_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    val_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {val_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "for i, (train_dataset, val_dataset) in enumerate(k_fold.split(dataset)):\n",
    "    model = GNN().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_loader, model, loss_fn, optimizer)\n",
    "        valid(val_loader, model, loss_fn)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(k_fold.split(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorcheeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseDataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorcheeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorcheeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
      "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/torch/lib/python3.8/site-packages/torcheeg/model_selection/k_fold.py\n",
      "\u001b[0;31mType:\u001b[0m      method\n"
     ]
    }
   ],
   "source": [
    "k_fold.split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Data(edge_index=[2, 686], x=[128, 4], edge_weight=[686]), 1)\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(edge_index=[2, 686], x=[128, 4], edge_weight=[686]), 2)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::scatter_reduce.two_out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/hugofluhr/Documents/Cours/NML/NetworkMachineLearning_2023/notebooks_hugo/eeg_numpydataset.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hugofluhr/Documents/Cours/NML/NetworkMachineLearning_2023/notebooks_hugo/eeg_numpydataset.ipynb#X55sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hugofluhr/Documents/Cours/NML/NetworkMachineLearning_2023/notebooks_hugo/eeg_numpydataset.ipynb#X55sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hugofluhr/Documents/Cours/NML/NetworkMachineLearning_2023/notebooks_hugo/eeg_numpydataset.ipynb#X55sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     train(train_loader, model, loss_fn, optimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hugofluhr/Documents/Cours/NML/NetworkMachineLearning_2023/notebooks_hugo/eeg_numpydataset.ipynb#X55sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     valid(val_loader, model, loss_fn)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hugofluhr/Documents/Cours/NML/NetworkMachineLearning_2023/notebooks_hugo/eeg_numpydataset.ipynb#X55sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/hugofluhr/Documents/Cours/NML/NetworkMachineLearning_2023/notebooks_hugo/eeg_numpydataset.ipynb Cell 20\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hugofluhr/Documents/Cours/NML/NetworkMachineLearning_2023/notebooks_hugo/eeg_numpydataset.ipynb#X55sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m y \u001b[39m=\u001b[39m batch[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hugofluhr/Documents/Cours/NML/NetworkMachineLearning_2023/notebooks_hugo/eeg_numpydataset.ipynb#X55sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Compute prediction error\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hugofluhr/Documents/Cours/NML/NetworkMachineLearning_2023/notebooks_hugo/eeg_numpydataset.ipynb#X55sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m pred \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hugofluhr/Documents/Cours/NML/NetworkMachineLearning_2023/notebooks_hugo/eeg_numpydataset.ipynb#X55sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hugofluhr/Documents/Cours/NML/NetworkMachineLearning_2023/notebooks_hugo/eeg_numpydataset.ipynb#X55sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Backpropagation\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/hugofluhr/Documents/Cours/NML/NetworkMachineLearning_2023/notebooks_hugo/eeg_numpydataset.ipynb Cell 20\u001b[0m in \u001b[0;36mGNN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hugofluhr/Documents/Cours/NML/NetworkMachineLearning_2023/notebooks_hugo/eeg_numpydataset.ipynb#X55sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hugofluhr/Documents/Cours/NML/NetworkMachineLearning_2023/notebooks_hugo/eeg_numpydataset.ipynb#X55sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     x, edge_index, batch \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_index, data\u001b[39m.\u001b[39mbatch\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hugofluhr/Documents/Cours/NML/NetworkMachineLearning_2023/notebooks_hugo/eeg_numpydataset.ipynb#X55sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x, edge_index))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hugofluhr/Documents/Cours/NML/NetworkMachineLearning_2023/notebooks_hugo/eeg_numpydataset.ipynb#X55sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hugofluhr/Documents/Cours/NML/NetworkMachineLearning_2023/notebooks_hugo/eeg_numpydataset.ipynb#X55sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(conv(x, edge_index))\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py:252\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[0;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    247\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mThe usage of \u001b[39m\u001b[39m'\u001b[39m\u001b[39medge_attr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39madd_self_loops\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39msimultaneously is currently not yet supported for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39medge_index\u001b[39m\u001b[39m'\u001b[39m\u001b[39m in a \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSparseTensor\u001b[39m\u001b[39m'\u001b[39m\u001b[39m form\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    251\u001b[0m \u001b[39m# edge_updater_type: (alpha: OptPairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m alpha \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medge_updater(edge_index, alpha\u001b[39m=\u001b[39;49malpha, edge_attr\u001b[39m=\u001b[39;49medge_attr)\n\u001b[1;32m    254\u001b[0m \u001b[39m# propagate_type: (x: OptPairTensor, alpha: Tensor)\u001b[39;00m\n\u001b[1;32m    255\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpropagate(edge_index, x\u001b[39m=\u001b[39mx, alpha\u001b[39m=\u001b[39malpha, size\u001b[39m=\u001b[39msize)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:531\u001b[0m, in \u001b[0;36mMessagePassing.edge_updater\u001b[0;34m(self, edge_index, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m coll_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_collect(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_edge_user_args, edge_index, size,\n\u001b[1;32m    528\u001b[0m                           kwargs)\n\u001b[1;32m    530\u001b[0m edge_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minspector\u001b[39m.\u001b[39mdistribute(\u001b[39m'\u001b[39m\u001b[39medge_update\u001b[39m\u001b[39m'\u001b[39m, coll_dict)\n\u001b[0;32m--> 531\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medge_update(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49medge_kwargs)\n\u001b[1;32m    533\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_edge_update_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    534\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (edge_index, kwargs), out)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py:295\u001b[0m, in \u001b[0;36mGATConv.edge_update\u001b[0;34m(self, alpha_j, alpha_i, edge_attr, index, ptr, size_i)\u001b[0m\n\u001b[1;32m    292\u001b[0m     alpha \u001b[39m=\u001b[39m alpha \u001b[39m+\u001b[39m alpha_edge\n\u001b[1;32m    294\u001b[0m alpha \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mleaky_relu(alpha, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnegative_slope)\n\u001b[0;32m--> 295\u001b[0m alpha \u001b[39m=\u001b[39m softmax(alpha, index, ptr, size_i)\n\u001b[1;32m    296\u001b[0m alpha \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(alpha, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[1;32m    297\u001b[0m \u001b[39mreturn\u001b[39;00m alpha\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch_geometric/utils/softmax.py:65\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(src, index, ptr, num_nodes, dim)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39melif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     N \u001b[39m=\u001b[39m maybe_num_nodes(index, num_nodes)\n\u001b[0;32m---> 65\u001b[0m     src_max \u001b[39m=\u001b[39m scatter(src\u001b[39m.\u001b[39;49mdetach(), index, dim, dim_size\u001b[39m=\u001b[39;49mN, reduce\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     66\u001b[0m     out \u001b[39m=\u001b[39m src \u001b[39m-\u001b[39m src_max\u001b[39m.\u001b[39mindex_select(dim, index)\n\u001b[1;32m     67\u001b[0m     out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mexp()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch_geometric/utils/scatter.py:98\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     93\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe usage of `scatter(reduce=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mreduce\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m                           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcan be accelerated via the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch-scatter\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m                           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m package, but it was not found\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     97\u001b[0m         index \u001b[39m=\u001b[39m broadcast(index, src, dim)\n\u001b[0;32m---> 98\u001b[0m         \u001b[39mreturn\u001b[39;00m src\u001b[39m.\u001b[39;49mnew_zeros(size)\u001b[39m.\u001b[39;49mscatter_reduce_(\n\u001b[1;32m     99\u001b[0m             dim, index, src, reduce\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ma\u001b[39;49m\u001b[39m{\u001b[39;49;00mreduce\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m, include_self\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    101\u001b[0m     \u001b[39mreturn\u001b[39;00m torch_scatter\u001b[39m.\u001b[39mscatter(src, index, dim, dim_size\u001b[39m=\u001b[39mdim_size,\n\u001b[1;32m    102\u001b[0m                                  reduce\u001b[39m=\u001b[39mreduce)\n\u001b[1;32m    104\u001b[0m \u001b[39m# For \"mul\" reduction, we prefer `scatter_reduce_` on CPU:\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::scatter_reduce.two_out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "from torcheeg import model_selection\n",
    "train_dataset, val_dataset = model_selection.train_test_split(dataset)\n",
    "device = 'mps'\n",
    "model = GNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    valid(val_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
